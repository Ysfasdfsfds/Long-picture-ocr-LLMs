"""
OCRé•¿å›¾å¤„ç†ä¸»ç¨‹åº
é‡æ„ç‰ˆæœ¬ - ä¿æŒä¸åŸç‰ˆç›¸åŒçš„åŠŸèƒ½å’Œè¾“å‡º
"""

import os
import shutil
import logging
import time
from pathlib import Path
from typing import Optional, Dict, List, Tuple

from .core.image_slicer import ImageSlicer
from .core.ocr_engine import OCREngine
from .core.chat_analyzer import ChatAnalyzer
from .processors.avatar_detector import AvatarDetector
from .processors.content_marker import ContentMarker
from .processors.deduplicator import Deduplicator
from .exporters.json_exporter import JsonExporter
from .models.ocr_result import OCRItem, AvatarItem
from .utils.config import Config
from .utils.visualization import Visualizer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class LongImageOCR:
    """é•¿å›¾OCRå¤„ç†å™¨ï¼ˆé‡æ„ç‰ˆï¼‰"""
    
    def __init__(self, config_path: str = "default_rapidocr.yaml"):
        """
        åˆå§‹åŒ–é•¿å›¾OCRå¤„ç†å™¨
        
        Args:
            config_path: RapidOCRé…ç½®æ–‡ä»¶è·¯å¾„
        """
        # åŠ è½½é…ç½®
        self.config = Config()
        self.config.ocr.config_path = config_path
        
        # åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        self.image_slicer = ImageSlicer(self.config)
        self.ocr_engine = OCREngine(self.config)
        self.avatar_detector = AvatarDetector(self.config)
        self.content_marker = ContentMarker(self.config)
        self.deduplicator = Deduplicator(self.config)
        self.chat_analyzer = ChatAnalyzer(self.config)
        self.json_exporter = JsonExporter(self.config)
        self.visualizer = Visualizer(self.config)
        
        # å­˜å‚¨å¤„ç†ç»“æœ
        self.original_image = None
        self.all_ocr_items = []
        self.all_avatar_items = []
        self.marked_ocr_items = []
        self.chat_session = None
        
        logger.info("é•¿å›¾OCRå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def process_long_image(self, image_path: str) -> Dict:
        """
        å¤„ç†é•¿å›¾çš„å®Œæ•´æµç¨‹
        
        Args:
            image_path: å›¾åƒè·¯å¾„
            
        Returns:
            å¤„ç†ç»“æœæ‘˜è¦
        """
        logger.info(f"å¼€å§‹å¤„ç†é•¿å›¾: {image_path}")
        
        # è®°å½•æ€»ä½“å¼€å§‹æ—¶é—´
        total_start_time = time.time()
        step_times = {}
        
        try:
            # 1. åˆ‡åˆ†å›¾åƒ
            step_start = time.time()
            logger.info("æ­¥éª¤1: åˆ‡åˆ†å›¾åƒ...")
            self.original_image, slice_infos = self.image_slicer.slice_image(image_path)
            step_times['step1_slice_image'] = time.time() - step_start
            logger.info(f"æ­¥éª¤1 å®Œæˆï¼Œè€—æ—¶: {step_times['step1_slice_image']:.2f}ç§’")
            
            # æ—©æœŸæ£€æµ‹å›¾ç‰‡ç±»å‹å¹¶é†’ç›®æ‰“å°
            self._early_platform_detection(image_path)
            
            # 2. è®¡ç®—x_cropå€¼
            step_start = time.time()
            logger.info("æ­¥éª¤2: è®¡ç®—x_cropå€¼...")
            x_crop = self.avatar_detector.calculate_x_crop(slice_infos)
            step_times['step2_calculate_x_crop'] = time.time() - step_start
            logger.info(f"æ­¥éª¤2 å®Œæˆï¼Œè€—æ—¶: {step_times['step2_calculate_x_crop']:.2f}ç§’")
            
            # å¯è§†åŒ–é€‰ä¸­çš„æ¡†
            if hasattr(self.avatar_detector, 'slice_x_crop_values'):
                selected_box = self._find_selected_box()
                if selected_box:
                    self.visualizer.visualize_selected_box(
                        selected_box, slice_infos, self.original_image
                    )
            
            # 3. å¤„ç†åˆ‡ç‰‡
            step_start = time.time()
            logger.info("æ­¥éª¤3: å¤„ç†åˆ‡ç‰‡...")
            slice_stats = self._process_slices(slice_infos, x_crop)
            step_times['step3_process_slices'] = time.time() - step_start
            step_times['step3_details'] = slice_stats  # ä¿å­˜è¯¦ç»†ç»Ÿè®¡
            logger.info(f"æ­¥éª¤3 å®Œæˆï¼Œè€—æ—¶: {step_times['step3_process_slices']:.2f}ç§’")
            
            # 4. å»é‡å¤„ç†
            step_start = time.time()
            logger.info("æ­¥éª¤4: å»é‡å¤„ç†...")
            self._deduplicate_results()
            step_times['step4_deduplicate'] = time.time() - step_start
            logger.info(f"æ­¥éª¤4 å®Œæˆï¼Œè€—æ—¶: {step_times['step4_deduplicate']:.2f}ç§’")
            
            # 4.5 ç”ŸæˆåŸå›¾OCRå¯è§†åŒ–ï¼ˆä½¿ç”¨å»é‡åçš„æ•°æ®ï¼‰
            use_detailed_timing = getattr(self.config, 'enable_detailed_ocr_timing', True)
            if use_detailed_timing and self.all_ocr_items:
                try:
                    logger.info("å¼€å§‹ç”ŸæˆåŸå›¾OCRå¯è§†åŒ–ï¼ˆä½¿ç”¨å»é‡åæ•°æ®ï¼‰...")
                    self.ocr_engine.visualize_full_image_ocr_results(
                        self.original_image, self.all_ocr_items
                    )
                    logger.info("åŸå›¾OCRå¯è§†åŒ–å®Œæˆ")
                except Exception as vis_e:
                    logger.warning(f"åŸå›¾OCRå¯è§†åŒ–å¤±è´¥: {vis_e}")
            
            # 5. åˆ¤æ–­å¹³å°ç±»å‹ï¼ˆæœ€ç»ˆç¡®è®¤ï¼‰
            step_start = time.time()
            is_feishu = self._is_feishu_screenshot()
            platform = "é£ä¹¦" if is_feishu else "å¾®ä¿¡/è“ä¿¡/é’‰é’‰"
            self._print_final_platform_detection(platform, is_feishu)
            step_times['step5_platform_detection'] = time.time() - step_start
            logger.info(f"æ­¥éª¤5 (å¹³å°æ£€æµ‹) å®Œæˆï¼Œè€—æ—¶: {step_times['step5_platform_detection']:.2f}ç§’")
            
            # 6. å†…å®¹æ ‡è®°
            step_start = time.time()
            logger.info("æ­¥éª¤6: å†…å®¹æ ‡è®°...")
            self.marked_ocr_items = self.content_marker.mark_content(
                self.all_ocr_items, self.all_avatar_items, self.original_image
            )
            step_times['step6_content_marking'] = time.time() - step_start
            logger.info(f"æ­¥éª¤6 å®Œæˆï¼Œè€—æ—¶: {step_times['step6_content_marking']:.2f}ç§’")
            
            # 7. åˆ†æèŠå¤©æ¶ˆæ¯
            step_start = time.time()
            logger.info("æ­¥éª¤7: åˆ†æèŠå¤©æ¶ˆæ¯...")
            self.chat_session = self.chat_analyzer.analyze(self.marked_ocr_items)
            step_times['step7_chat_analysis'] = time.time() - step_start
            logger.info(f"æ­¥éª¤7 å®Œæˆï¼Œè€—æ—¶: {step_times['step7_chat_analysis']:.2f}ç§’")
            
            # 8. å¯¼å‡ºç»“æœ
            step_start = time.time()
            logger.info("æ­¥éª¤8: å¯¼å‡ºç»“æœ...")
            self._export_results()
            
            # å¯¼å‡ºè¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡æ•°æ®
            self._export_timing_details(step_times)
            
            step_times['step8_export_results'] = time.time() - step_start
            logger.info(f"æ­¥éª¤8 å®Œæˆï¼Œè€—æ—¶: {step_times['step8_export_results']:.2f}ç§’")
            
            # 9. åˆ›å»ºå¤„ç†æ€»ç»“
            step_start = time.time()
            self.visualizer.create_process_summary_image(
                self.original_image, slice_infos,
                len(self.all_ocr_items), len(self.all_avatar_items)
            )
            step_times['step9_create_summary'] = time.time() - step_start
            logger.info(f"æ­¥éª¤9 (åˆ›å»ºæ€»ç»“) å®Œæˆï¼Œè€—æ—¶: {step_times['step9_create_summary']:.2f}ç§’")
            
            # è®¡ç®—æ€»ä½“æ‰§è¡Œæ—¶é—´
            total_time = time.time() - total_start_time
            step_times['total_time'] = total_time
            
            # æ‰“å°è¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡
            self._print_timing_summary(step_times)
            
            # è¿”å›ç»“æœæ‘˜è¦ï¼ˆåŒ…å«æ—¶é—´ä¿¡æ¯ï¼‰
            return self._create_summary(step_times)
            
        except Exception as e:
            total_time = time.time() - total_start_time
            logger.error(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}ï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’", exc_info=True)
            raise
    
    def _early_platform_detection(self, image_path: str):
        """åœ¨å¤„ç†æ—©æœŸè¿›è¡Œå¹³å°ç±»å‹æ£€æµ‹å¹¶é†’ç›®æ‰“å°"""
        print("\n" + "="*60)
        print("ğŸ” å›¾ç‰‡ç±»å‹æ£€æµ‹ - åˆæ­¥åˆ†æ")
        print("="*60)
        
        # åŸºäºæ–‡ä»¶åçš„åˆæ­¥åˆ¤æ–­
        image_name = os.path.basename(image_path)
        print(f"ğŸ“ è¾“å…¥å›¾ç‰‡: {image_name}")
        
        # è¿›è¡Œåˆæ­¥OCRæ£€æµ‹ï¼ˆä½¿ç”¨å°‘é‡åˆ‡ç‰‡ï¼‰
        logger.info("è¿›è¡Œåˆæ­¥OCRæ£€æµ‹ä»¥ç¡®å®šå¹³å°ç±»å‹...")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šæ£€æµ‹é€»è¾‘
        print("â³ æ­£åœ¨åˆ†æå›¾ç‰‡å†…å®¹ç‰¹å¾...")
        print("="*60 + "\n")
    
    def _print_final_platform_detection(self, platform: str, is_feishu: bool):
        """é†’ç›®æ‰“å°æœ€ç»ˆçš„å¹³å°æ£€æµ‹ç»“æœ"""
        print("\n" + "*"*60)
        print("ğŸ¯ å›¾ç‰‡ç±»å‹æ£€æµ‹ - æœ€ç»ˆç»“æœ")
        print("*"*60)
        
        if is_feishu:
            print("ğŸ“± æ£€æµ‹ç»“æœ: é£ä¹¦ (Feishu)")
            print("âœ… æ£€æµ‹çŠ¶æ€: æˆåŠŸè¯†åˆ«")
            print("ğŸ”§ å¤„ç†æ¨¡å¼: é£ä¹¦ä¸“ç”¨æ¨¡å¼")
            print("ğŸ“‹ ç‰¹å¾è¯†åˆ«: æ£€æµ‹åˆ°é£ä¹¦ç‰¹æœ‰ç•Œé¢å…ƒç´ ")
        else:
            print("ğŸ“± æ£€æµ‹ç»“æœ: å¾®ä¿¡/è“ä¿¡/é’‰é’‰")
            print("â„¹ï¸  æ£€æµ‹çŠ¶æ€: é»˜è®¤è¯†åˆ«")
            print("ğŸ”§ å¤„ç†æ¨¡å¼: é€šç”¨èŠå¤©æ¨¡å¼")
            print("ğŸ“‹ ç‰¹å¾è¯†åˆ«: æœªæ£€æµ‹åˆ°é£ä¹¦ç‰¹å¾ï¼Œä½¿ç”¨é€šç”¨å¤„ç†")
        
        print("*"*60)
        logger.info(f"ğŸ¯ æœ€ç»ˆç¡®è®¤å¹³å°ç±»å‹: {platform}")
        print()
    
    def _process_slices(self, slice_infos: List, x_crop: Optional[int]) -> Dict[str, float]:
        """å¤„ç†æ‰€æœ‰åˆ‡ç‰‡ï¼Œæ”¯æŒè¯¦ç»†è®¡æ—¶æ¨¡å¼"""
        all_ocr_items = []
        all_avatar_items = []
        
        # è¯¦ç»†æ—¶é—´ç»Ÿè®¡
        slice_times = {}
        total_ocr_time = 0
        total_avatar_time = 0
        
        logger.info(f"å¼€å§‹å¤„ç† {len(slice_infos)} ä¸ªåˆ‡ç‰‡...")
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è¯¦ç»†è®¡æ—¶æ¨¡å¼
        use_detailed_timing = getattr(self.config, 'enable_detailed_ocr_timing', True)
        
        if use_detailed_timing:
            logger.info("ğŸ” å¯ç”¨è¯¦ç»†OCRè®¡æ—¶æ¨¡å¼ - å°†åˆ†åˆ«è®°å½•Detectionå’ŒRecognitionæ—¶é—´")
        
        for slice_info in slice_infos:
            slice_idx = slice_info.slice_index
            slice_start_time = time.time()
            
            logger.info(f"å¤„ç†åˆ‡ç‰‡ {slice_idx}...")
            
            # OCRè¯†åˆ« - æ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„å¤„ç†æ–¹æ³•
            ocr_start_time = time.time()
            if use_detailed_timing:
                # ä½¿ç”¨è¯¦ç»†è®¡æ—¶çš„OCRå¤„ç†
                slice_ocr_result = self.ocr_engine.process_slice_with_detailed_timing(slice_info)
            else:
                # ä½¿ç”¨å¸¸è§„OCRå¤„ç†
                slice_ocr_result = self.ocr_engine.process_slice(slice_info)
            ocr_time = time.time() - ocr_start_time
            total_ocr_time += ocr_time
            
            # å¤´åƒæ£€æµ‹ - å•ç‹¬è®¡æ—¶
            avatar_start_time = time.time()
            avatar_items = self.avatar_detector.detect_avatars(slice_info, x_crop)
            avatar_time = time.time() - avatar_start_time
            total_avatar_time += avatar_time
            
            # è®°å½•å•ä¸ªåˆ‡ç‰‡çš„è¯¦ç»†æ—¶é—´
            slice_total_time = time.time() - slice_start_time
            slice_times[f'slice_{slice_idx}'] = {
                'total_time': slice_total_time,
                'ocr_time': ocr_time,
                'avatar_time': avatar_time,
                'ocr_items_count': len(slice_ocr_result.ocr_items),
                'avatar_items_count': len(avatar_items)
            }
            
            logger.info(f"åˆ‡ç‰‡ {slice_idx} å®Œæˆ: OCR={ocr_time:.2f}s, å¤´åƒ={avatar_time:.2f}s, æ€»è®¡={slice_total_time:.2f}s")
            
            # æ·»åŠ åˆ°ç»“æœä¸­
            all_ocr_items.extend(slice_ocr_result.ocr_items)
            all_avatar_items.extend(avatar_items)
            
            # æ›´æ–°åˆ‡ç‰‡ç»“æœ
            slice_ocr_result.avatar_items = avatar_items
        
        # å¦‚æœå¯ç”¨äº†è¯¦ç»†è®¡æ—¶ï¼Œå¯¼å‡ºè¯¦ç»†çš„è®¡æ—¶è®°å½•
        if use_detailed_timing:
            self.ocr_engine.export_slice_timing_records()
        
        # ä¿å­˜åˆ°å®ä¾‹å˜é‡
        self.all_ocr_items = all_ocr_items
        self.all_avatar_items = all_avatar_items
        
        # åŸå›¾OCRå¯è§†åŒ–ç§»è‡³å»é‡å¤„ç†ä¹‹åè¿›è¡Œ
        # æ±‡æ€»ç»Ÿè®¡
        summary_stats = {
            'total_slices': len(slice_infos),
            'total_ocr_time': total_ocr_time,
            'total_avatar_time': total_avatar_time,
            'average_ocr_time': total_ocr_time / len(slice_infos) if slice_infos else 0,
            'average_avatar_time': total_avatar_time / len(slice_infos) if slice_infos else 0,
            'slice_details': slice_times,
            'detailed_timing_enabled': use_detailed_timing
        }
        
        # æ‰“å°è¯¦ç»†ç»Ÿè®¡
        self._print_slice_timing_summary(summary_stats)
        
        return summary_stats
    
    def _deduplicate_results(self):
        """å»é‡å¤„ç†"""
        self.all_ocr_items, self.all_avatar_items = self.deduplicator.deduplicate(
            self.all_ocr_items, self.all_avatar_items
        )
    
    def _is_feishu_screenshot(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºé£ä¹¦æˆªå›¾"""
        keywords = self.config.get_feishu_keywords()
        detected_keywords = set()
        
        for item in self.all_ocr_items:
            text = item.text
            for keyword in keywords:
                if keyword in text:
                    detected_keywords.add(keyword)
        
        is_feishu = len(detected_keywords) == len(keywords)
        
        # è¯¦ç»†è®°å½•æ£€æµ‹ç»“æœ
        if is_feishu:
            logger.info(f"âœ“ é£ä¹¦æ£€æµ‹æˆåŠŸ - æ£€æµ‹åˆ°æ‰€æœ‰å…³é”®è¯: {detected_keywords}")
        else:
            missing_keywords = set(keywords) - detected_keywords
            logger.info(f"âœ— é£ä¹¦æ£€æµ‹å¤±è´¥ - æ£€æµ‹åˆ°å…³é”®è¯: {detected_keywords}, ç¼ºå¤±å…³é”®è¯: {missing_keywords}")
        
        return is_feishu
    
    def _export_results(self):
        """å¯¼å‡ºæ‰€æœ‰ç»“æœ"""
        # å¯¼å‡ºæ ‡è®°åçš„OCRç»“æœ
        self.json_exporter.export_marked_ocr_results(self.marked_ocr_items)
        
        # å¯¼å‡ºç»“æ„åŒ–èŠå¤©æ¶ˆæ¯
        self.json_exporter.export_chat_messages(self.chat_session)
        
        # å¯¼å‡ºæ±‡æ€»æ•°æ®
        self.json_exporter.export_summary_data(
            self.all_ocr_items, self.all_avatar_items, self.marked_ocr_items
        )
    
    def _find_selected_box(self) -> Optional[Tuple]:
        """æ‰¾åˆ°é€‰ä¸­çš„ç›®æ ‡æ¡†"""
        # ä»avatar_detectorçš„å†…éƒ¨æ•°æ®ä¸­æŸ¥æ‰¾
        if not hasattr(self.avatar_detector, 'slice_x_crop_values'):
            return None
        
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»calculate_x_cropçš„è¿”å›å€¼ä¸­è·å–
        # ä¸ºäº†å…¼å®¹åŸç‰ˆï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿè¿”å›ä¸€ä¸ªå€¼
        for slice_idx, box in self.avatar_detector.slice_x_crop_values.items():
            if box is not None:
                x, y, w, h = box
                return (x, y, w, h, slice_idx)
        
        return None
    
    def _print_timing_summary(self, step_times: Dict[str, float]):
        """æ‰“å°è¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡æ‘˜è¦"""
        print("\n" + "â±ï¸ "*30)
        print("â±ï¸  å¤„ç†æ—¶é—´ç»Ÿè®¡æ‘˜è¦")
        print("â±ï¸ "*30)
        
        # æ‰“å°å„ä¸ªæ­¥éª¤çš„æ—¶é—´
        step_names = {
            'step1_slice_image': 'æ­¥éª¤1: åˆ‡åˆ†å›¾åƒ',
            'step2_calculate_x_crop': 'æ­¥éª¤2: è®¡ç®—x_cropå€¼',
            'step3_process_slices': 'æ­¥éª¤3: å¤„ç†åˆ‡ç‰‡(OCR+å¤´åƒæ£€æµ‹)',
            'step4_deduplicate': 'æ­¥éª¤4: å»é‡å¤„ç†',
            'step5_platform_detection': 'æ­¥éª¤5: å¹³å°ç±»å‹æ£€æµ‹',
            'step6_content_marking': 'æ­¥éª¤6: å†…å®¹æ ‡è®°',
            'step7_chat_analysis': 'æ­¥éª¤7: åˆ†æèŠå¤©æ¶ˆæ¯',
            'step8_export_results': 'æ­¥éª¤8: å¯¼å‡ºç»“æœ',
            'step9_create_summary': 'æ­¥éª¤9: åˆ›å»ºå¤„ç†æ€»ç»“'
        }
        
        for step_key, step_name in step_names.items():
            if step_key in step_times:
                time_value = step_times[step_key]
                print(f"ğŸ“Š {step_name}: {time_value:.2f}ç§’")
        
        print(f"\nğŸ æ€»ä½“æ‰§è¡Œæ—¶é—´: {step_times['total_time']:.2f}ç§’")
        
        # è®¡ç®—æœ€è€—æ—¶çš„æ­¥éª¤ï¼ˆåªæ¯”è¾ƒæ•°å€¼ç±»å‹çš„æ­¥éª¤æ—¶é—´ï¼‰
        step_only_times = {k: v for k, v in step_times.items() 
                          if k.startswith('step') and isinstance(v, (int, float))}
        if step_only_times:
            slowest_step = max(step_only_times, key=step_only_times.get)
            slowest_time = step_only_times[slowest_step]
            slowest_name = step_names.get(slowest_step, slowest_step)
            print(f"ğŸŒ æœ€è€—æ—¶æ­¥éª¤: {slowest_name} ({slowest_time:.2f}ç§’)")
        
        print("â±ï¸ "*30 + "\n")
    
    def _print_slice_timing_summary(self, slice_stats: Dict):
        """æ‰“å°åˆ‡ç‰‡å¤„ç†çš„è¯¦ç»†æ—¶é—´ç»Ÿè®¡"""
        print("\n" + "ğŸ”"*30)
        print("ğŸ” æ­¥éª¤3: åˆ‡ç‰‡å¤„ç†è¯¦ç»†ç»Ÿè®¡")
        print("ğŸ”"*30)
        
        # åŸºæœ¬ç»Ÿè®¡
        total_slices = slice_stats['total_slices']
        total_ocr_time = slice_stats['total_ocr_time']
        total_avatar_time = slice_stats['total_avatar_time']
        avg_ocr_time = slice_stats['average_ocr_time']
        avg_avatar_time = slice_stats['average_avatar_time']
        
        print(f"ğŸ“Š åˆ‡ç‰‡æ€»æ•°: {total_slices}")
        print(f"ğŸ”¤ OCRè¯†åˆ«æ€»è€—æ—¶: {total_ocr_time:.2f}ç§’ (å¹³å‡: {avg_ocr_time:.2f}ç§’/ç‰‡)")
        print(f"ğŸ‘¤ å¤´åƒæ£€æµ‹æ€»è€—æ—¶: {total_avatar_time:.2f}ç§’ (å¹³å‡: {avg_avatar_time:.2f}ç§’/ç‰‡)")
        
        # åˆ†ææœ€è€—æ—¶çš„åˆ‡ç‰‡
        slice_details = slice_stats['slice_details']
        if slice_details:
            # æŒ‰æ€»æ—¶é—´æ’åºæ‰¾æœ€è€—æ—¶çš„åˆ‡ç‰‡
            sorted_slices = sorted(slice_details.items(), 
                                 key=lambda x: x[1]['total_time'], reverse=True)
            
            slowest_slice = sorted_slices[0]
            slice_name = slowest_slice[0]
            slice_data = slowest_slice[1]
            
            print(f"ğŸŒ æœ€è€—æ—¶åˆ‡ç‰‡: {slice_name}")
            print(f"   â”œâ”€ æ€»è€—æ—¶: {slice_data['total_time']:.2f}ç§’")
            print(f"   â”œâ”€ OCRè€—æ—¶: {slice_data['ocr_time']:.2f}ç§’")
            print(f"   â”œâ”€ å¤´åƒæ£€æµ‹: {slice_data['avatar_time']:.2f}ç§’")
            print(f"   â”œâ”€ OCRè¯†åˆ«æ•°: {slice_data['ocr_items_count']}ä¸ª")
            print(f"   â””â”€ å¤´åƒæ•°é‡: {slice_data['avatar_items_count']}ä¸ª")
            
            # æ˜¾ç¤ºå‰3ä¸ªæœ€è€—æ—¶çš„åˆ‡ç‰‡æ¦‚è§ˆ
            print(f"\nğŸ“ˆ è€—æ—¶TOP3åˆ‡ç‰‡:")
            for i, (slice_name, slice_data) in enumerate(sorted_slices[:3]):
                print(f"   {i+1}. {slice_name}: {slice_data['total_time']:.2f}s "
                      f"(OCR: {slice_data['ocr_time']:.2f}s, "
                      f"å¤´åƒ: {slice_data['avatar_time']:.2f}s)")
        
        print("ğŸ”"*30 + "\n")
    
    def _create_summary(self, step_times: Dict[str, float] = None) -> Dict:
        """åˆ›å»ºå¤„ç†ç»“æœæ‘˜è¦"""
        stats = self.chat_session.get_statistics() if self.chat_session else {}
        
        summary = {
            "total_ocr_items": len(self.all_ocr_items),
            "total_avatars": len(self.all_avatar_items),
            "total_messages": stats.get('total', 0),
            "chat_messages": stats.get('chat', 0),
            "time_messages": stats.get('time', 0),
            "my_messages": stats.get('my_chat', 0)
        }
        
        # æ·»åŠ æ—¶é—´ç»Ÿè®¡ä¿¡æ¯ï¼ˆåªä¿ç•™å…³é”®æ•°æ®ï¼Œé¿å…è¿‡äºå†—é•¿ï¼‰
        if step_times:
            # åªä¿ç•™åŸºæœ¬çš„æ­¥éª¤æ—¶é—´ï¼Œä¸åŒ…å«è¯¦ç»†çš„åˆ‡ç‰‡æ•°æ®
            clean_step_times = {}
            for k, v in step_times.items():
                if k != 'total_time' and not k.endswith('_details') and isinstance(v, (int, float)):
                    clean_step_times[k] = round(v, 2)
            
            summary['timing'] = {
                'total_time': round(step_times.get('total_time', 0), 2),
                'step_times': clean_step_times
            }
            
            # å¦‚æœæœ‰æ­¥éª¤3çš„è¯¦ç»†ç»Ÿè®¡ï¼Œåªä¿ç•™æ±‡æ€»ä¿¡æ¯
            if 'step3_details' in step_times:
                step3_details = step_times['step3_details']
                summary['timing']['step3_summary'] = {
                    'total_slices': step3_details.get('total_slices', 0),
                    'total_ocr_time': round(step3_details.get('total_ocr_time', 0), 2),
                    'total_avatar_time': round(step3_details.get('total_avatar_time', 0), 2),
                    'average_ocr_time': round(step3_details.get('average_ocr_time', 0), 3),
                    'average_avatar_time': round(step3_details.get('average_avatar_time', 0), 3)
                }
        
        return summary
    
    def _export_timing_details(self, step_times: Dict):
        """å¯¼å‡ºè¯¦ç»†çš„æ—¶é—´ç»Ÿè®¡æ•°æ®åˆ°JSONæ–‡ä»¶"""
        import json
        from pathlib import Path
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = Path("output_json")
        output_dir.mkdir(exist_ok=True)
        
        # å‡†å¤‡å®Œæ•´çš„æ—¶é—´ç»Ÿè®¡æ•°æ®
        timing_data = {
            "timestamp": str(time.strftime("%Y-%m-%d %H:%M:%S")),
            "total_execution_time": step_times.get('total_time', 0),
            "step_summary": {},
            "step3_detailed_analysis": None
        }
        
        # æ·»åŠ å„æ­¥éª¤çš„åŸºæœ¬æ—¶é—´ç»Ÿè®¡
        step_names = {
            'step1_slice_image': 'æ­¥éª¤1: åˆ‡åˆ†å›¾åƒ',
            'step2_calculate_x_crop': 'æ­¥éª¤2: è®¡ç®—x_cropå€¼',
            'step3_process_slices': 'æ­¥éª¤3: å¤„ç†åˆ‡ç‰‡(OCR+å¤´åƒæ£€æµ‹)',
            'step4_deduplicate': 'æ­¥éª¤4: å»é‡å¤„ç†',
            'step5_platform_detection': 'æ­¥éª¤5: å¹³å°ç±»å‹æ£€æµ‹',
            'step6_content_marking': 'æ­¥éª¤6: å†…å®¹æ ‡è®°',
            'step7_chat_analysis': 'æ­¥éª¤7: åˆ†æèŠå¤©æ¶ˆæ¯',
            'step8_export_results': 'æ­¥éª¤8: å¯¼å‡ºç»“æœ',
            'step9_create_summary': 'æ­¥éª¤9: åˆ›å»ºå¤„ç†æ€»ç»“'
        }
        
        for step_key, step_name in step_names.items():
            if step_key in step_times and isinstance(step_times[step_key], (int, float)):
                timing_data["step_summary"][step_key] = {
                    "name": step_name,
                    "time_seconds": round(step_times[step_key], 3),
                    "percentage": round((step_times[step_key] / step_times.get('total_time', 1)) * 100, 1)
                }
        
        # æ·»åŠ æ­¥éª¤3çš„è¯¦ç»†åˆ†æ
        if 'step3_details' in step_times:
            step3_details = step_times['step3_details']
            
            # åŸºæœ¬æ±‡æ€»
            timing_data["step3_detailed_analysis"] = {
                "summary": {
                    "total_slices": step3_details.get('total_slices', 0),
                    "total_ocr_time": round(step3_details.get('total_ocr_time', 0), 3),
                    "total_avatar_time": round(step3_details.get('total_avatar_time', 0), 3),
                    "average_ocr_time": round(step3_details.get('average_ocr_time', 0), 3),
                    "average_avatar_time": round(step3_details.get('average_avatar_time', 0), 3),
                    "ocr_percentage": round((step3_details.get('total_ocr_time', 0) / step3_details.get('total_ocr_time', 1) + step3_details.get('total_avatar_time', 0)) * 100, 1) if (step3_details.get('total_ocr_time', 0) + step3_details.get('total_avatar_time', 0)) > 0 else 0
                },
                "slice_details": {}
            }
            
            # æ¯ä¸ªåˆ‡ç‰‡çš„è¯¦ç»†æ•°æ®
            slice_details = step3_details.get('slice_details', {})
            for slice_name, slice_data in slice_details.items():
                timing_data["step3_detailed_analysis"]["slice_details"][slice_name] = {
                    "total_time": round(slice_data.get('total_time', 0), 3),
                    "ocr_time": round(slice_data.get('ocr_time', 0), 3),
                    "avatar_time": round(slice_data.get('avatar_time', 0), 3),
                    "ocr_items_count": slice_data.get('ocr_items_count', 0),
                    "avatar_items_count": slice_data.get('avatar_items_count', 0),
                    "efficiency": {
                        "ocr_items_per_second": round(slice_data.get('ocr_items_count', 0) / max(slice_data.get('ocr_time', 0.001), 0.001), 2),
                        "total_items_per_second": round((slice_data.get('ocr_items_count', 0) + slice_data.get('avatar_items_count', 0)) / max(slice_data.get('total_time', 0.001), 0.001), 2)
                    }
                }
            
            # æ·»åŠ æ€§èƒ½åˆ†æ
            if slice_details:
                sorted_slices = sorted(slice_details.items(), key=lambda x: x[1]['total_time'], reverse=True)
                timing_data["step3_detailed_analysis"]["performance_analysis"] = {
                    "slowest_slice": {
                        "name": sorted_slices[0][0],
                        "time": round(sorted_slices[0][1]['total_time'], 3),
                        "reason": "most_time_consuming"
                    },
                    "fastest_slice": {
                        "name": sorted_slices[-1][0],
                        "time": round(sorted_slices[-1][1]['total_time'], 3),
                        "reason": "least_time_consuming"
                    },
                    "top_3_slowest": [
                        {
                            "name": slice_name,
                            "time": round(slice_data['total_time'], 3),
                            "ocr_percentage": round((slice_data['ocr_time'] / slice_data['total_time']) * 100, 1) if slice_data['total_time'] > 0 else 0
                        }
                        for slice_name, slice_data in sorted_slices[:3]
                    ]
                }
        
        # å¯¼å‡ºåˆ°æ–‡ä»¶
        output_file = output_dir / "timing_analysis.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(timing_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"è¯¦ç»†æ—¶é—´ç»Ÿè®¡å·²å¯¼å‡ºåˆ°: {output_file}")
        print(f"ğŸ“ è¯¦ç»†æ—¶é—´ç»Ÿè®¡å·²ä¿å­˜åˆ°: {output_file}")
    
    def process_with_llm(self, user_question: str, llm_processor=None):
        """
        ä½¿ç”¨LLMå¤„ç†ç”¨æˆ·é—®é¢˜ï¼ˆä¿æŒæ¥å£å…¼å®¹ï¼‰
        
        Args:
            user_question: ç”¨æˆ·é—®é¢˜
            llm_processor: LLMå¤„ç†å™¨ï¼ˆå¯é€‰ï¼‰
        """
        if self.chat_session and llm_processor:
            messages = self.chat_session.to_dict()['chat_messages']
            return llm_processor(user_question, messages)
        else:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„èŠå¤©æ¶ˆæ¯æˆ–LLMå¤„ç†å™¨")
            return None


def main():
    """ä¸»å‡½æ•°"""
    # æ¸…ç†è¾“å‡ºç›®å½•
    if os.path.exists("output_images"):
        shutil.rmtree("output_images")
    if os.path.exists("output_json"):
        shutil.rmtree("output_json")
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    processor = LongImageOCR(config_path="./default_rapidocr.yaml")
    
    # å¤„ç†é•¿å›¾
    image_path = r"images/image copy 9.png"
    
    try:
        result = processor.process_long_image(image_path)
        print("\nå¤„ç†ç»“æœæ‘˜è¦:")
        for key, value in result.items():
            print(f"  {key}: {value}")
        
        # æ¨¡æ‹Ÿä¸LLMçš„äº¤äº’
        print("\nå¤„ç†å®Œæˆï¼")
        
    except Exception as e:
        print(f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()