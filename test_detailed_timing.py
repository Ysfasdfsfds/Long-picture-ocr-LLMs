#!/usr/bin/env python3
"""
è¯¦ç»†OCRè®¡æ—¶åŠŸèƒ½æµ‹è¯•è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„è¯¦ç»†è®¡æ—¶åŠŸèƒ½æ¥åˆ†åˆ«è®°å½•detectionå’Œrecognitionçš„æ¨ç†æ—¶é—´
"""

import sys
import os
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.main import LongImageOCR
from src.utils.config import Config

def test_detailed_ocr_timing():
    """æµ‹è¯•è¯¦ç»†OCRè®¡æ—¶åŠŸèƒ½"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•è¯¦ç»†OCRè®¡æ—¶åŠŸèƒ½")
    print("="*60)
    
    # åˆ›å»ºé…ç½®ï¼Œå¯ç”¨è¯¦ç»†è®¡æ—¶
    config = Config()
    config.enable_detailed_ocr_timing = True  # å¯ç”¨è¯¦ç»†è®¡æ—¶
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - è¯¦ç»†è®¡æ—¶æ¨¡å¼: {'âœ… å¯ç”¨' if config.enable_detailed_ocr_timing else 'âŒ ç¦ç”¨'}")
    print(f"  - OCRé…ç½®æ–‡ä»¶: {config.ocr.config_path}")
    print(f"  - æ–‡æœ¬ç½®ä¿¡åº¦é˜ˆå€¼: {config.ocr.text_score_threshold}")
    print(f"  - åˆ‡ç‰‡é«˜åº¦: {config.image.slice_height}px")
    print(f"  - é‡å åŒºåŸŸ: {config.image.overlap}px")
    print()
    
    # åˆå§‹åŒ–å¤„ç†å™¨
    try:
        processor = LongImageOCR(config_path="./default_rapidocr.yaml")
        # æ‰‹åŠ¨è®¾ç½®é…ç½®
        processor.config = config
        print("âœ… OCRå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ OCRå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # æŸ¥æ‰¾æµ‹è¯•å›¾ç‰‡
    test_image_dirs = ["images", "test_images", "."]
    test_image_patterns = ["*.png", "*.jpg", "*.jpeg"]
    
    test_image_path = None
    for test_dir in test_image_dirs:
        if not os.path.exists(test_dir):
            continue
        for pattern in test_image_patterns:
            images = list(Path(test_dir).glob(pattern))
            if images:
                test_image_path = str(images[0])  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å›¾ç‰‡
                break
        if test_image_path:
            break
    
    if not test_image_path:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡ï¼Œè¯·å°†å›¾ç‰‡æ”¾åœ¨ä»¥ä¸‹ç›®å½•ä¹‹ä¸€ï¼š")
        for test_dir in test_image_dirs:
            print(f"   - {test_dir}/")
        return
    
    print(f"ğŸ“¸ æµ‹è¯•å›¾ç‰‡: {test_image_path}")
    print()
    
    # å¤„ç†å›¾ç‰‡
    try:
        print("ğŸ”„ å¼€å§‹å¤„ç†...")
        start_time = time.time()
        
        result = processor.process_long_image(test_image_path)
        
        end_time = time.time()
        total_processing_time = end_time - start_time
        
        print(f"\nâœ… å¤„ç†å®Œæˆï¼æ€»è€—æ—¶: {total_processing_time:.2f}ç§’")
        print()
        
        # æ˜¾ç¤ºå¤„ç†ç»“æœæ‘˜è¦
        print("ğŸ“Š å¤„ç†ç»“æœæ‘˜è¦:")
        for key, value in result.items():
            if key != 'timing':  # timingä¿¡æ¯å¤ªè¯¦ç»†ï¼Œå•ç‹¬å¤„ç†
                print(f"  - {key}: {value}")
        print()
        
        # æ˜¾ç¤ºè®¡æ—¶ä¿¡æ¯
        if 'timing' in result:
            timing = result['timing']
            print("â±ï¸  æ€»ä½“è®¡æ—¶ç»Ÿè®¡:")
            print(f"  - æ€»æ‰§è¡Œæ—¶é—´: {timing.get('total_time', 0):.2f}ç§’")
            
            if 'step3_summary' in timing:
                step3 = timing['step3_summary']
                print(f"  - æ€»åˆ‡ç‰‡æ•°: {step3.get('total_slices', 0)}")
                print(f"  - OCRæ€»è€—æ—¶: {step3.get('total_ocr_time', 0):.2f}ç§’")
                print(f"  - å¹³å‡OCRæ—¶é—´: {step3.get('average_ocr_time', 0):.3f}ç§’/ç‰‡")
                print(f"  - å¤´åƒæ£€æµ‹æ€»è€—æ—¶: {step3.get('total_avatar_time', 0):.2f}ç§’")
                print(f"  - å¹³å‡å¤´åƒæ£€æµ‹æ—¶é—´: {step3.get('average_avatar_time', 0):.3f}ç§’/ç‰‡")
        print()
        
        # æ£€æŸ¥è¯¦ç»†è®¡æ—¶æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
        timing_file = Path("output_json/slice_ocr_detailed_timing.json")
        if timing_file.exists():
            print("âœ… è¯¦ç»†è®¡æ—¶è®°å½•æ–‡ä»¶å·²ç”Ÿæˆ:")
            print(f"   ğŸ“ {timing_file}")
            
            # ç®€å•ç»Ÿè®¡æ–‡ä»¶å†…å®¹
            import json
            try:
                with open(timing_file, 'r', encoding='utf-8') as f:
                    timing_data = json.load(f)
                
                if 'summary' in timing_data:
                    summary = timing_data['summary']
                    print(f"\nğŸ” è¯¦ç»†è®¡æ—¶åˆ†æ (æ¥è‡ª{timing_file.name}):")
                    
                    if 'timing_summary' in summary:
                        ts = summary['timing_summary']
                        print(f"  ğŸ“Š æ—¶é—´åˆ†å¸ƒç»Ÿè®¡:")
                        print(f"    - Detectionæ€»æ—¶é—´: {ts.get('total_detection_time', 0):.3f}ç§’")
                        print(f"    - Recognitionæ€»æ—¶é—´: {ts.get('total_recognition_time', 0):.3f}ç§’")
                        print(f"    - é¢„å¤„ç†æ€»æ—¶é—´: {ts.get('total_preprocessing_time', 0):.3f}ç§’")
                        print(f"    - åå¤„ç†æ€»æ—¶é—´: {ts.get('total_postprocessing_time', 0):.3f}ç§’")
                        print()
                        print(f"    - å¹³å‡Detectionæ—¶é—´: {ts.get('average_detection_time', 0):.3f}ç§’/ç‰‡")
                        print(f"    - å¹³å‡Recognitionæ—¶é—´: {ts.get('average_recognition_time', 0):.3f}ç§’/ç‰‡")
                    
                    if 'performance_analysis' in summary:
                        pa = summary['performance_analysis']
                        if 'time_distribution' in pa:
                            td = pa['time_distribution']
                            print(f"  ğŸ“ˆ æ—¶é—´å æ¯”åˆ†æ:")
                            print(f"    - Detectionå æ¯”: {td.get('detection_percentage', 0):.1f}%")
                            print(f"    - Recognitionå æ¯”: {td.get('recognition_percentage', 0):.1f}%")
                            print(f"    - é¢„å¤„ç†å æ¯”: {td.get('preprocessing_percentage', 0):.1f}%")
                            print(f"    - åå¤„ç†å æ¯”: {td.get('postprocessing_percentage', 0):.1f}%")
                        
                        if 'slowest_slice' in pa and 'fastest_slice' in pa:
                            print(f"  ğŸŒ æœ€æ…¢åˆ‡ç‰‡: slice_{pa['slowest_slice']['slice_index']} ({pa['slowest_slice']['total_time']:.3f}s)")
                            print(f"  ğŸƒ æœ€å¿«åˆ‡ç‰‡: slice_{pa['fastest_slice']['slice_index']} ({pa['fastest_slice']['total_time']:.3f}s)")
                    
                    if 'slice_details' in timing_data:
                        slice_count = len(timing_data['slice_details'])
                        print(f"  ğŸ“‹ è®°å½•äº† {slice_count} ä¸ªåˆ‡ç‰‡çš„è¯¦ç»†è®¡æ—¶æ•°æ®")
            
            except Exception as e:
                print(f"  âš ï¸  è¯»å–è¯¦ç»†è®¡æ—¶æ–‡ä»¶å‡ºé”™: {e}")
        else:
            print("âš ï¸  è¯¦ç»†è®¡æ—¶è®°å½•æ–‡ä»¶æœªç”Ÿæˆ")
        
        print()
        print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print("\nğŸ’¡ æç¤º:")
        print("  - è¯¦ç»†è®¡æ—¶æ•°æ®å·²ä¿å­˜åˆ° output_json/slice_ocr_detailed_timing.json")
        print("  - å¯ä»¥é€šè¿‡ä¿®æ”¹ Config.enable_detailed_ocr_timing = False æ¥ç¦ç”¨è¯¦ç»†è®¡æ—¶")
        print("  - è¯¦ç»†è®¡æ—¶ä¼šç•¥å¾®å¢åŠ å¤„ç†æ—¶é—´ï¼Œä½†èƒ½æä¾›æ›´ç²¾ç¡®çš„æ€§èƒ½åˆ†æ")
    
    except Exception as e:
        print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def test_comparison():
    """å¯¹æ¯”æµ‹è¯•ï¼šæ™®é€šæ¨¡å¼ vs è¯¦ç»†è®¡æ—¶æ¨¡å¼"""
    print("\n" + "="*60)
    print("ğŸ”„ å¼€å§‹å¯¹æ¯”æµ‹è¯•ï¼šæ™®é€šæ¨¡å¼ vs è¯¦ç»†è®¡æ—¶æ¨¡å¼")
    print("="*60)
    
    # æŸ¥æ‰¾æµ‹è¯•å›¾ç‰‡
    test_image_dirs = ["images", "test_images", "."]
    test_image_patterns = ["*.png", "*.jpg", "*.jpeg"]
    
    test_image_path = None
    for test_dir in test_image_dirs:
        if not os.path.exists(test_dir):
            continue
        for pattern in test_image_patterns:
            images = list(Path(test_dir).glob(pattern))
            if images:
                test_image_path = str(images[0])  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„å›¾ç‰‡
                break
        if test_image_path:
            break
    
    if not test_image_path:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•å›¾ç‰‡ï¼Œè·³è¿‡å¯¹æ¯”æµ‹è¯•")
        return
    
    results = {}
    
    # æµ‹è¯•ä¸¤ç§æ¨¡å¼
    for mode_name, enable_timing in [("æ™®é€šæ¨¡å¼", False), ("è¯¦ç»†è®¡æ—¶æ¨¡å¼", True)]:
        print(f"\nğŸ§ª æµ‹è¯• {mode_name}...")
        
        config = Config()
        config.enable_detailed_ocr_timing = enable_timing
        
        try:
            processor = LongImageOCR(config_path="./default_rapidocr.yaml")
            processor.config = config
            
            start_time = time.time()
            result = processor.process_long_image(test_image_path)
            end_time = time.time()
            
            results[mode_name] = {
                'total_time': end_time - start_time,
                'result': result
            }
            
            print(f"  âœ… {mode_name}å®Œæˆï¼Œè€—æ—¶: {results[mode_name]['total_time']:.2f}ç§’")
            
        except Exception as e:
            print(f"  âŒ {mode_name}æµ‹è¯•å¤±è´¥: {e}")
            results[mode_name] = None
    
    # å¯¹æ¯”ç»“æœ
    print(f"\nğŸ“Š å¯¹æ¯”ç»“æœ:")
    if all(results.values()):
        normal_time = results["æ™®é€šæ¨¡å¼"]['total_time']
        detailed_time = results["è¯¦ç»†è®¡æ—¶æ¨¡å¼"]['total_time']
        overhead = detailed_time - normal_time
        overhead_percent = (overhead / normal_time) * 100
        
        print(f"  - æ™®é€šæ¨¡å¼è€—æ—¶: {normal_time:.2f}ç§’")
        print(f"  - è¯¦ç»†è®¡æ—¶æ¨¡å¼è€—æ—¶: {detailed_time:.2f}ç§’")
        print(f"  - æ—¶é—´å¼€é”€: {overhead:.2f}ç§’ ({overhead_percent:.1f}%)")
        
        if overhead_percent < 5:
            print(f"  ğŸ“ˆ ç»“è®º: è¯¦ç»†è®¡æ—¶çš„æ€§èƒ½å¼€é”€å¾ˆå° (<5%)")
        elif overhead_percent < 15:
            print(f"  ğŸ“ˆ ç»“è®º: è¯¦ç»†è®¡æ—¶çš„æ€§èƒ½å¼€é”€é€‚ä¸­ (<15%)")
        else:
            print(f"  ğŸ“ˆ ç»“è®º: è¯¦ç»†è®¡æ—¶çš„æ€§èƒ½å¼€é”€è¾ƒé«˜ (>15%)")
    else:
        print("  âš ï¸  å¯¹æ¯”æµ‹è¯•ä¸å®Œæ•´ï¼Œæ— æ³•å¾—å‡ºç»“è®º")

if __name__ == "__main__":
    print("ğŸ” è¯¦ç»†OCRè®¡æ—¶åŠŸèƒ½æµ‹è¯•")
    print("æœ¬è„šæœ¬å°†æµ‹è¯•æ–°å¢çš„OCRè¯¦ç»†è®¡æ—¶åŠŸèƒ½ï¼Œåˆ†åˆ«è®°å½•æ¯ä¸ªåˆ‡ç‰‡çš„detectionå’Œrecognitionæ¨ç†æ—¶é—´")
    print()
    
    # åŸºæœ¬æµ‹è¯•
    test_detailed_ocr_timing()
    
    # å¯¹æ¯”æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
    user_input = input("\næ˜¯å¦è¿›è¡Œå¯¹æ¯”æµ‹è¯•ï¼Ÿ(y/nï¼Œé»˜è®¤n): ").lower().strip()
    if user_input in ['y', 'yes']:
        test_comparison()
    
    print(f"\nâœ¨ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")